{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structures for Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents:\n",
    "\n",
    "- B-Trees for range searches of numerical and date values-\n",
    "- Inverted Index for searching relevant documents based on text.\n",
    "- Doc Values (Columnar data representatios) for fast field/column-wise aggregation operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [`README.md`](./README.md) and [`../README.md`](../README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider with have the following set of documents:\n",
    "\n",
    "```\n",
    "[\n",
    "  { \"id\": 1, \"name\": \"Product A\", \"price\": 10 },\n",
    "  { \"id\": 2, \"name\": \"Product B\", \"price\": 20 },\n",
    "  { \"id\": 3, \"name\": \"Product C\", \"price\": 15 },\n",
    "  { \"id\": 4, \"name\": \"Product D\", \"price\": 25 },\n",
    "  { \"id\": 5, \"name\": \"Product E\", \"price\": 30 }\n",
    "]\n",
    "```\n",
    "\n",
    "We want to build a B-Tree for them to be able to perform range-based search and filtering.\n",
    "We want to store the document ids in the nodes, but all tree operations are done based on the price value of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BTreeNode:\n",
    "    def __init__(self, t, leaf=False):\n",
    "        self.t = t  # Minimum degree (defines the range for number of keys)\n",
    "        self.leaf = leaf\n",
    "        self.keys = []  # Array of keys\n",
    "        self.values = []  # Array of values (document IDs)\n",
    "        self.children = []  # Array of child pointers\n",
    "\n",
    "    def insert_non_full(self, key, value):\n",
    "        i = len(self.keys) - 1\n",
    "\n",
    "        if self.leaf:\n",
    "            self.keys.append(0)\n",
    "            self.values.append(0)\n",
    "            while i >= 0 and self.keys[i] > key:\n",
    "                self.keys[i + 1] = self.keys[i]\n",
    "                self.values[i + 1] = self.values[i]\n",
    "                i -= 1\n",
    "            self.keys[i + 1] = key\n",
    "            self.values[i + 1] = value\n",
    "        else:\n",
    "            while i >= 0 and self.keys[i] > key:\n",
    "                i -= 1\n",
    "            if len(self.children[i + 1].keys) == 2 * self.t - 1:\n",
    "                self.split_child(i + 1, self.children[i + 1])\n",
    "                if self.keys[i + 1] < key:\n",
    "                    i += 1\n",
    "            self.children[i + 1].insert_non_full(key, value)\n",
    "\n",
    "    def split_child(self, i, y):\n",
    "        t = self.t\n",
    "        z = BTreeNode(t, y.leaf)\n",
    "        self.children.insert(i + 1, z)\n",
    "        self.keys.insert(i, y.keys[t - 1])\n",
    "        self.values.insert(i, y.values[t - 1])\n",
    "        z.keys = y.keys[t:(2 * t - 1)]\n",
    "        z.values = y.values[t:(2 * t - 1)]\n",
    "        y.keys = y.keys[0:(t - 1)]\n",
    "        y.values = y.values[0:(t - 1)]\n",
    "\n",
    "        if not y.leaf:\n",
    "            z.children = y.children[t:(2 * t)]\n",
    "            y.children = y.children[0:t]\n",
    "\n",
    "class BTree:\n",
    "    def __init__(self, t):\n",
    "        self.root = BTreeNode(t, True)\n",
    "        self.t = t\n",
    "\n",
    "    def insert(self, key, value):\n",
    "        root = self.root\n",
    "        if len(root.keys) == 2 * self.t - 1:\n",
    "            temp = BTreeNode(self.t, False)\n",
    "            temp.children.insert(0, root)\n",
    "            temp.split_child(0, root)\n",
    "            i = 0\n",
    "            if temp.keys[0] < key:\n",
    "                i += 1\n",
    "            temp.children[i].insert_non_full(key, value)\n",
    "            self.root = temp\n",
    "        else:\n",
    "            root.insert_non_full(key, value)\n",
    "\n",
    "    def print_tree(self, node, lvl=0):\n",
    "        print(\"Level\", lvl, \":\", list(zip(node.keys, node.values)))\n",
    "        lvl += 1\n",
    "        if len(node.children) > 0:\n",
    "            for child in node.children:\n",
    "                self.print_tree(child, lvl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 0 : [(15, 3)]\n",
      "Level 1 : [(10, 1)]\n",
      "Level 1 : [(20, 2), (25, 4), (30, 5)]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "btree = BTree(2)  # B-tree with minimum degree 2\n",
    "documents = [\n",
    "    {\"id\": 1, \"price\": 10},\n",
    "    {\"id\": 2, \"price\": 20},\n",
    "    {\"id\": 3, \"price\": 15},\n",
    "    {\"id\": 4, \"price\": 25},\n",
    "    {\"id\": 5, \"price\": 30}\n",
    "]\n",
    "\n",
    "for doc in documents:\n",
    "    btree.insert(doc[\"price\"], doc[\"id\"])\n",
    "\n",
    "btree.print_tree(btree.root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [`README.md`](./README.md) and [`../README.md`](../README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider with have the following set of documents (same as before):\n",
    "\n",
    "```\n",
    "[\n",
    "  { \"id\": 1, \"name\": \"Product A\", \"price\": 10 },\n",
    "  { \"id\": 2, \"name\": \"Product B\", \"price\": 20 },\n",
    "  { \"id\": 3, \"name\": \"Product C\", \"price\": 15 },\n",
    "  { \"id\": 4, \"name\": \"Product D\", \"price\": 25 },\n",
    "  { \"id\": 5, \"name\": \"Product E\", \"price\": 30 }\n",
    "]\n",
    "```\n",
    "\n",
    "We want to build an inverted index for the field `name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "  { \"id\": 1, \"name\": \"Product A\", \"price\": 10 },\n",
    "  { \"id\": 2, \"name\": \"Product B\", \"price\": 20 },\n",
    "  { \"id\": 3, \"name\": \"Product C\", \"price\": 15 },\n",
    "  { \"id\": 4, \"name\": \"Product D\", \"price\": 25 },\n",
    "  { \"id\": 5, \"name\": \"Product E\", \"price\": 30 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, ['Product', 'A']), (2, ['Product', 'B']), (3, ['Product', 'C']), (4, ['Product', 'D']), (5, ['Product', 'E'])]\n"
     ]
    }
   ],
   "source": [
    "### --- Tokenization\n",
    "tokenized_docs = []\n",
    "for doc in documents:\n",
    "    tokens = doc['name'].split()\n",
    "    tokenized_docs.append((doc['id'], tokens))\n",
    "\n",
    "print(tokenized_docs)\n",
    "# Output: [(1, ['Product', 'A']), (2, ['Product', 'B']), (3, ['Product', 'C', 'Product', 'A'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: defaultdict(<class 'int'>, {'product': 1, 'a': 1}), 2: defaultdict(<class 'int'>, {'product': 1, 'b': 1}), 3: defaultdict(<class 'int'>, {'product': 1, 'c': 1}), 4: defaultdict(<class 'int'>, {'product': 1, 'd': 1}), 5: defaultdict(<class 'int'>, {'product': 1, 'e': 1})}\n"
     ]
    }
   ],
   "source": [
    "### -- Compute Term Frequencies (TF)\n",
    "from collections import defaultdict\n",
    "\n",
    "tf = defaultdict(lambda: defaultdict(int))\n",
    "for doc_id, tokens in tokenized_docs:\n",
    "    for token in tokens:\n",
    "        tf[doc_id][token.lower()] += 1\n",
    "\n",
    "print(dict(tf))\n",
    "# Output: {1: {'product': 1, 'a': 1}, 2: {'product': 1, 'b': 1}, 3: {'product': 2, 'c': 1, 'a': 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 0.0, 'a': 1.6094379124341003, 'b': 1.6094379124341003, 'c': 1.6094379124341003, 'd': 1.6094379124341003, 'e': 1.6094379124341003}\n"
     ]
    }
   ],
   "source": [
    "### -- Compute Inverse Document Frequencies (IDF)\n",
    "import math\n",
    "\n",
    "df = defaultdict(int)\n",
    "for doc_id, tokens in tokenized_docs:\n",
    "    for token in set(tokens):\n",
    "        df[token.lower()] += 1\n",
    "\n",
    "idf = {term: math.log(len(documents) / df[term]) for term in df}\n",
    "\n",
    "print(idf)\n",
    "# Output: {'product': 0.0, 'a': 0.4054651081081644, 'b': 1.0986122886681098, 'c': 1.0986122886681098}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: defaultdict(<class 'float'>, {'product': 0.0, 'a': 1.6094379124341003}), 2: defaultdict(<class 'float'>, {'product': 0.0, 'b': 1.6094379124341003}), 3: defaultdict(<class 'float'>, {'product': 0.0, 'c': 1.6094379124341003}), 4: defaultdict(<class 'float'>, {'product': 0.0, 'd': 1.6094379124341003}), 5: defaultdict(<class 'float'>, {'product': 0.0, 'e': 1.6094379124341003})}\n"
     ]
    }
   ],
   "source": [
    "### -- Compute TF-IDF\n",
    "tf_idf = defaultdict(lambda: defaultdict(float))\n",
    "for doc_id, tokens in tokenized_docs:\n",
    "    for token in tokens:\n",
    "        tf_idf[doc_id][token.lower()] = tf[doc_id][token.lower()] * idf[token.lower()]\n",
    "\n",
    "print(dict(tf_idf))\n",
    "# Output: {1: {'product': 0.0, 'a': 0.4054651081081644}, 2: {'product': 0.0, 'b': 1.0986122886681098}, 3: {'product': 0.0, 'c': 1.0986122886681098, 'a': 0.4054651081081644}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': [(1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0)], 'a': [(1, 1.6094379124341003)], 'b': [(2, 1.6094379124341003)], 'c': [(3, 1.6094379124341003)], 'd': [(4, 1.6094379124341003)], 'e': [(5, 1.6094379124341003)]}\n"
     ]
    }
   ],
   "source": [
    "### -- Build the Inverted Index\n",
    "inverted_index = defaultdict(list)\n",
    "for doc_id, scores in tf_idf.items():\n",
    "    for term, score in scores.items():\n",
    "        inverted_index[term].append((doc_id, score))\n",
    "\n",
    "print(dict(inverted_index))\n",
    "# Output: {'product': [(1, 0.0), (2, 0.0), (3, 0.0)], 'a': [(1, 0.4054651081081644), (3, 0.4054651081081644)], 'b': [(2, 1.0986122886681098)], 'c': [(3, 1.0986122886681098)]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc Values, Columnar Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [`README.md`](./README.md) and [`../README.md`](../README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider with have the following set of documents (same as before):\n",
    "\n",
    "```\n",
    "[\n",
    "  { \"id\": 1, \"name\": \"Product A\", \"price\": 10 },\n",
    "  { \"id\": 2, \"name\": \"Product B\", \"price\": 20 },\n",
    "  { \"id\": 3, \"name\": \"Product C\", \"price\": 15 },\n",
    "  { \"id\": 4, \"name\": \"Product D\", \"price\": 25 },\n",
    "  { \"id\": 5, \"name\": \"Product E\", \"price\": 30 }\n",
    "]\n",
    "```\n",
    "\n",
    "We want to build a Doc Value or columnar representation of `price` to be able to compute fast field aggragation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "  { \"id\": 1, \"name\": \"Product A\", \"price\": 10 },\n",
    "  { \"id\": 2, \"name\": \"Product B\", \"price\": 20 },\n",
    "  { \"id\": 3, \"name\": \"Product C\", \"price\": 15 },\n",
    "  { \"id\": 4, \"name\": \"Product D\", \"price\": 25 },\n",
    "  { \"id\": 5, \"name\": \"Product E\", \"price\": 30 }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize numpy array for prices\n",
    "prices = np.zeros(len(documents))\n",
    "\n",
    "# Initialize bitstring\n",
    "bitstring = np.zeros(len(documents), dtype=int)\n",
    "\n",
    "# Initialize dictionary to map document IDs to array indices\n",
    "doc_id_to_index = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prices Array: [10. 20. 15. 25. 30.]\n",
      "Bitstring: [1 1 1 1 1]\n",
      "Document ID to Index Mapping: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4}\n"
     ]
    }
   ],
   "source": [
    "for idx, doc in enumerate(documents):\n",
    "    prices[idx] = doc[\"price\"]\n",
    "    bitstring[idx] = 1  # 1 indicates the presence of the document\n",
    "    doc_id_to_index[doc[\"id\"]] = idx\n",
    "\n",
    "print(\"Prices Array:\", prices)\n",
    "print(\"Bitstring:\", bitstring)\n",
    "print(\"Document ID to Index Mapping:\", doc_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Bitstring: [0 1 0 ... 1 1 1]\n",
      "Mean Price: 49.99163888795988\n"
     ]
    }
   ],
   "source": [
    "# Switch off documents with IDs 1 and 3\n",
    "bitstring[doc_id_to_index[1]] = 0\n",
    "bitstring[doc_id_to_index[3]] = 0\n",
    "\n",
    "print(\"Updated Bitstring:\", bitstring)\n",
    "\n",
    "# Compute the mean price using masked array\n",
    "mean_price = np.ma.masked_array(prices, mask=bitstring == 0).mean()\n",
    "\n",
    "# Alternative\n",
    "# masked_prices = prices[bitstring == 1]\n",
    "# mean_price = masked_prices.mean()\n",
    "# Which option is faster and more efficient?\n",
    "# The new array will require more memory,\n",
    "# the speed is benchmarked below...\n",
    "\n",
    "print(\"Mean Price:\", mean_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking of Masked vs. New Array Aggregation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New array mean price: 50.00747511111111, Time: 0.057581424713134766 seconds\n",
      "Masked array mean price: 50.00747511111111, Time: 0.04833984375 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Large example dataset\n",
    "num_docs = 10_000_000\n",
    "documents = [{\"id\": i, \"price\": np.random.randint(1, 100)} for i in range(num_docs)]\n",
    "\n",
    "# Initialize numpy array for prices\n",
    "prices = np.zeros(num_docs)\n",
    "\n",
    "# Initialize bitstring\n",
    "bitstring = np.ones(num_docs, dtype=int)\n",
    "\n",
    "# Populate the arrays and mappings\n",
    "for idx, doc in enumerate(documents):\n",
    "    prices[idx] = doc[\"price\"]\n",
    "\n",
    "# Switch off some documents\n",
    "bitstring[::10] = 0  # Switch off every 10th document\n",
    "\n",
    "# Benchmark creating a new array\n",
    "start_time = time.time()\n",
    "masked_prices = prices[bitstring == 1]\n",
    "mean_price_new_array = masked_prices.mean()\n",
    "new_array_time = time.time() - start_time\n",
    "\n",
    "# Benchmark applying a mask\n",
    "start_time = time.time()\n",
    "mean_price_mask = np.ma.masked_array(prices, mask=bitstring == 0).mean()\n",
    "mask_time = time.time() - start_time\n",
    "\n",
    "print(f\"New array mean price: {mean_price_new_array}, Time: {new_array_time} seconds\")\n",
    "print(f\"Masked array mean price: {mean_price_mask}, Time: {mask_time} seconds\")\n",
    "# The new array is almost 2x faster than the masked array approach\n",
    "# but that's maybe not always the case..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
